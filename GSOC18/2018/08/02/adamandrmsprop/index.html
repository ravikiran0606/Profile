<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Adam and RMSProp Optimizer - Implementation and Testing:- &middot; GSoC'18 @ CERN
    
  </title>

  <!--Mathjax-->
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <!-- CSS -->
  <link rel="stylesheet" href="/GSOC18/public/css/poole.css">
  <link rel="stylesheet" href="/GSOC18/public/css/syntax.css">
  <link rel="stylesheet" href="/GSOC18/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/GSOC18/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/GSOC18/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      <h1>
        <a href="/GSOC18/">
          GSoC'18 @ CERN
        </a>
      </h1>
      <p class="lead">Google Summer of Code 2018 Progress @ CERN-HSF by Ravi Kiran S.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/GSOC18/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/GSOC18//about/">About</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
    </nav>

    <p>Copyright &copy; Jekyll Themes 2018</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Adam and RMSProp Optimizer - Implementation and Testing:-</h1>
  <span class="post-date">02 Aug 2018</span>
  <p>In this blog post, I’ll be explaining the implementation of the Adam Optimizer, RMSProp optimizer with and without momentum approach.</p>

<h2 id="rmsprop-optimizer">RMSProp Optimizer:</h2>

<p>RMSprop is an unpublished, adaptive learning rate method proposed by Geoff Hinton. The main idea is <strong>“Divide the gradient by a running average of its recent magnitude”</strong>. It is similar to Adadelta but it is developed independently to overcome the disadvantages of the Adagrad algorithm.</p>

<p>Thus, the update is implemented as follows, ( similar to the tensorflow implementation )</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Vt = rho * Vt-1 + (1-rho) * currentSquaredGradients
Wt = momentum * Wt-1 + (learningRate * currentGradients) / (sqrt(Vt + epsilon))
theta = theta - Wt
</code></pre></div></div>

<p>So, one step of update is performed as,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\begin{split}
v_t &= \rho v_{t-1} + (1-\rho) \nabla_\theta^2 J( \theta) \\
w_t &= \gamma w_{t-1} + \dfrac{\eta}{\sqrt{v_t + \epsilon}} \nabla_\theta J( \theta)  \\  
\theta &= \theta - w_t
\end{split}
\end{align} %]]></script>

<h2 id="testing-rmsprop">Testing RMSProp:</h2>

<p>I used the same unit tests approach as for SGD optimizer. Have a look at <strong>Testing the SGD optimizer post</strong>.</p>

<div>
    <a href="https://plot.ly/~ravikiran0606/36/?share_key=dQ2PnWziGGbXA8mVVRDxK0" target="_blank" title="RMSPROPUTP" style="display: block; text-align: center;"><img src="https://plot.ly/~ravikiran0606/36.png?share_key=dQ2PnWziGGbXA8mVVRDxK0" alt="RMSPROPUTP" style="max-width: 100%;width: 600px;" width="600" onerror="this.onerror=null;this.src='https://plot.ly/404.png';" /></a>
    <script data-plotly="ravikiran0606:36" sharekey-plotly="dQ2PnWziGGbXA8mVVRDxK0" src="https://plot.ly/embed.js" async=""></script>
</div>

<div>
    <a href="https://plot.ly/~ravikiran0606/37/?share_key=sNfftgUs2x2JITp0XKOhDO" target="_blank" title="RMSPROPMUTP" style="display: block; text-align: center;"><img src="https://plot.ly/~ravikiran0606/37.png?share_key=sNfftgUs2x2JITp0XKOhDO" alt="RMSPROPMUTP" style="max-width: 100%;width: 600px;" width="600" onerror="this.onerror=null;this.src='https://plot.ly/404.png';" /></a>
    <script data-plotly="ravikiran0606:37" sharekey-plotly="sNfftgUs2x2JITp0XKOhDO" src="https://plot.ly/embed.js" async=""></script>
</div>

<p>The above figures shows the convergence of the training and testing errors for the RMSProp optimizer without and with momentum during the unit tests.</p>

<h2 id="adam-optimizer">Adam Optimizer:</h2>

<p>Adaptive Moment Estimation (Adam) is a method that computes adaptive learning rates for each parameter. It stores both the decaying average of the past gradients <script type="math/tex">m_t</script>, similar to momentum and also the decaying average of the past squared gradients <script type="math/tex">v_t</script>, similar to RMSprop and Adadelta. Thus, it combines the advantages of both the methods. Adam is the default choice of the optimizer for any application in general.</p>

<p>Thus, the update is implemented as follows, ( similar to the tensorflow implementation )</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mt = beta1 * Mt-1 + (1-beta1) * currentGradients
Vt = beta2 * Vt-1 + (1-beta2) * currentSquaredGradients
alpha = learningRate * sqrt(1 - beta2^t) / (1-beta1^t)
theta = theta - alpha * Mt / (sqrt(Vt) + epsilon)
</code></pre></div></div>

<p>So, one step of update is performed as,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\begin{split}
m_t &= \beta_1 m_{t-1} + (1-\beta_1) \nabla_\theta J( \theta) \\ 
v_t &= \beta_2 v_{t-1} + (1-\beta_2) \nabla_\theta^2 J( \theta) \\ 
\alpha &= \eta \dfrac{\sqrt{(1-\beta_2^t)}}{(1-\beta_1^t)} \\
\theta &= \theta - \alpha \dfrac{m_t}{\sqrt{v_t}+ \epsilon}
\end{split}
\end{align} %]]></script>

<h2 id="testing-adam">Testing Adam:</h2>

<p>I used the same unit tests approach as for SGD optimizer. Have a look at <strong>Testing the SGD optimizer post</strong>.</p>

<div>
    <a href="https://plot.ly/~ravikiran0606/35/?share_key=adux2BQhLVIq0OPUVU3pO0" target="_blank" title="ADAMUTP" style="display: block; text-align: center;"><img src="https://plot.ly/~ravikiran0606/35.png?share_key=adux2BQhLVIq0OPUVU3pO0" alt="ADAMUTP" style="max-width: 100%;width: 600px;" width="600" onerror="this.onerror=null;this.src='https://plot.ly/404.png';" /></a>
    <script data-plotly="ravikiran0606:35" sharekey-plotly="adux2BQhLVIq0OPUVU3pO0" src="https://plot.ly/embed.js" async=""></script>
</div>

<p>The above figure shows the convergence of the training and testing errors for the Adam Optimizer during the unit tests.</p>

<h2 id="references">References:</h2>

<p>1) <a href="https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer">RMSProp Optimizer - Tensorflow Implementation</a></p>

<p>2) <a href="https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer">Adam Optimizer - Tensorflow Implementation</a></p>

</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/GSOC18//2018/08/13/conclusion/">
            Conclusion:-
            <small>13 Aug 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/GSOC18//2018/08/12/prs/">
            List of PRs submitted:-
            <small>12 Aug 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/GSOC18//2018/08/10/comparison/">
            Comparison of various optimizers and future work:-
            <small>10 Aug 2018</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>

    </div>

  </body>
</html>
